df2 = dfS - df1 + 1
F = df2*Tsqd/(df1*dfS)
pval = pf(F, df1, df2, lower.tail = 0)
pval # .062559
# Using the R function manova():
fit = manova(Y ~ spouse)
summary(fit)
summary.aov(fit)
C
Y = X%*%t(C)
Y
# Using the R function manova():
fit = manova(Y ~ spouse)
pval # .062559
pval
C = rbind(c(-1, 1, 0, 0), c(0, -1, 1, 0), c(0, 0, -1, 1))
Y = X%*%t(C)
# Calc Tsqd:
# Using the R function manova():
fit = manova(Y ~ spouse)
summary(fit)
summary.aov(fit)
# Using the R function manova():
fit = manova(Y ~ spouse)
head(Y)
summary.aov(fit)
pval
# Using the R function manova():
fit = manova(Y ~ spouse)
summary(fit)
summary.aov(fit)
summary(fit)
# Level Profiles
dbar = colMeans(Y)
S = cov(Y)
cov.est = S/nrow(Y)
dfS = nrow(Y) - 1
df2 = dfS - df1 + 1
Fcalc = df2*Tsqd/(df1*dfS)
pval = pf(Fcalc, df1, df2, lower.tail = 0)
pval # .00015
C = rbind(c(-1, 1, 0, 0), c(0, -1, 1, 0), c(0, 0, -1, 1))
Y = X%*%t(C)
# Calc Tsqd:
ybar1 = colMeans(Y[spouse==1,])
ybar2 = colMeans(Y[spouse==2,])
n1 = nrow(Y[spouse==1,])
n2 = nrow(Y[spouse==2,])
dbar = ybar1 - ybar2
S1 = cov(Y[spouse==1,])
S2 = cov(Y[spouse==2,])
dfS = (n1-1) + (n2-1)
Spooled = ((n1-1)*S1 + (n2-1)*S2)/dfS
cov.est = (1/n1 + 1/n2)*Spooled
Tsqd = t(dbar)%*%solve(cov.est, dbar)
df1 = length(dbar)
df2 = dfS - df1 + 1
F = df2*Tsqd/(df1*dfS)
pval = pf(F, df1, df2, lower.tail = 0)
pval # .062559
# Using the R function manova():
fit = manova(Y ~ spouse)
summary(fit)
# Level Profiles
dbar = colMeans(Y)
df1 = length(dbar)
S = cov(Y)
cov.est = S/nrow(Y)
dfS = nrow(Y) - 1
Tsqd = t(dbar)%*%solve(cov.est, dbar)
df2 = dfS - df1 + 1
Fcalc = df2*Tsqd/(df1*dfS)
pval = pf(Fcalc, df1, df2, lower.tail = 0)
pval # .00015
C = rbind(c(-1, 1, 0, 0), c(0, -1, 1, 0), c(0, 0, -1, 1))
data <- read.table("T6-14.dat")
X = as.matrix(data[,1:4])
spouse = c(rep(1,30), rep(2,30))
spouse = as.factor(spouse)
xbar1 = colMeans(X[spouse==1,])
xbar2 = colMeans(X[spouse==2,])
# Plot of estimated profiles:
matplot(1:4, cbind(xbar1,xbar2), type = 'l', xaxp = c(1,4,3),
lty = 1, lwd =3, col= 1:2, xlab = "Criterion", ylab = "Average rating for criterion", main =
"Estimated profiles")
legend("topleft", c("husbands", "wives"), lty = 1, lwd = 2, col= 1:2)
Y = X%*%t(C)
# Using the R function manova():
fit = manova(Y ~ spouse)
summary(fit)
# Coincident
dbar = colMeans(Y)
df1 = length(dbar)
cov.est = S/nrow(Y)
dfS = nrow(Y) - 1
Tsqd = t(dbar)%*%solve(cov.est, dbar)
df2 = dfS - df1 + 1
Fcalc = df2*Tsqd/(df1*dfS)
pval = pf(Fcalc, df1, df2, lower.tail = 0)
pval # .00015
C = rbind(c(-1, 1, 0, 0), c(0, -1, 1, 0), c(0, 0, -1, 1))
Y = X%*%t(C)
# Using the R function manova():
fit = manova(Y ~ spouse)
summary(fit)
# Coincident
fit <- aov(rowSums(X) ~ spouse)
summary(fit)
# Coincident
x1 = rowSums(X[spouse==1,])
x2 = rowSums(X[spouse==2,])
t.test(x1,x2, var.equal = T) # pval = .2207
t.test(x1,x2) # Welch test; still pval = .2207
# Using the R function aov():
fit = aov(rowSums(X) ~ spouse)
summary(fit)
# Flatness
dbar = colMeans(Y)
df1 = length(dbar)
S = cov(Y)
# Flatness
dbar <- colMeans(Y)
df1 <- length(dbar)
S <- cov(Y)
dfS <- nrow(Y) - 1
Tsqd <- t(dbar)%*%solve(cov.est, dbar)
df2 <- dfS - df1 + 1
Fcalc <- df2*Tsqd/(df1*dfS)
pval <- pf(Fcalc, df1, df2, lower.tail = 0)
pval # .00015
Fcalc
df1
df2
library(matlib)
X <- as.matrix(read.table("T6-1.dat"))
log.X <- log(X)
diff <- cbind(log.X[,1] - log.X[,3], log.X[,2] - log.X[,4])
colnames(diff) = c("log BOD", "log SS")
dbar <- colMeans(diff)
Sd <- cov(diff)
n <- nrow(diff)
p <- ncol(diff)
n
T.calc <- n*t(dbar)%*%inv(Sd)%*%dbar
pf((((n-1)-p+1)/(p*(n-1)))*T.calc, p, n-2, lower.tail=FALSE)
T.calc
pf((((n-1)-p+1)/(p*(n-1)))*T.calc, p, n-2, lower.tail=FALSE)
library(matlib)
X <- as.matrix(read.table("T6-1.dat"))
log.X <- log(X)
diff <- cbind(log.X[,1] - log.X[,3], log.X[,2] - log.X[,4])
dbar <- colMeans(diff)
n <- nrow(diff)
p <- ncol(diff)
T.calc <- n*t(dbar)%*%inv(Sd)%*%dbar
T.calc
p
T.calc <- n*t(dbar)%*%inv(Sd)%*%dbar
T.calc
pf((((n-1)-p+1)/(p*(n-1)))*T.calc, p, n-2, lower.tail=FALSE)
(((n-1)-p+1)/(p*(n-1)))*T.calc
(((n-1)-p+1)/(p*(n-1)))
(((n-1)-p+1)/(p*(n-1)))
library(matlib)
X <- as.matrix(read.table("T6-1.dat"))
log.X <- log(X)
diff <- cbind(log.X[,1] - log.X[,3], log.X[,2] - log.X[,4])
colnames(diff) = c("log BOD", "log SS")
dbar <- colMeans(diff)
Sd <- cov(diff)
n <- nrow(diff)
p <- ncol(diff)
T.calc <- n*t(dbar)%*%inv(Sd)%*%dbar
p.val <- pf((((n-1)-p+1)/(p*(n-1)))*T.calc, p, n-2, lower.tail=FALSE)
(((n-1)-p+1)/(p*(n-1)))
c(T.calc, p.val)
pf(0.45,2,9,lower.tail = FALSE)
c(T.calc, p.val)
pf(0.45*T.calc,2,9,lower.tail = FALSE)
(((n-1)-p+1)/(p*(n-1)))*T.calc
alpha <- .05
m <- 2
alpham <- alpha/m
int <- matrix(nrow = m, ncol = 2, data = NA)
for(i in 1:m) {
psihat <- dbar[i]
sd_psihat <- sqrt(Sd[i,i]/n)
qT <- qt(alpham/2, n-1, lower.tail = 0)
int[i,] <- c(psihat - qT*sd_psihat, psihat + qT*sd_psihat)
}
int_Bon <- cbind(int[,1], dbar, int[,2])
colnames(int_Bon) <- c("lower", "dbar", "upper")
cat("Bonferroni intervals on the two marginal means","\n")
int_Bon
diff
plot(diff)
qqplot(diff)
diff[1]
diff[,1]
y <- qunif(ppoints(length(diff[,1])))
names(diff)
names(diff)
diff
qqplot(diff$"log BOD",y)
qqplot(diff[,1],y)
colnames(diff)
y = diff[,1]
v=qqnorm(y, ylab = colnames(diff)[1])
text(0, max(v$y-2), paste("corr = ", round(cor(v$x,v$y),3)))
v=qqnorm(y, ylab = colnames(diff)[1])
text(0, max(v$y-2), paste("corr = ", round(cor(v$x,v$y),3)))
v
cor(v$x,v$y)
max(v$y-2)
text(0, max(v$y-2), paste("corr = ", round(cor(v$x,v$y),3)))
y = diff[,2]
v=qqnorm(y, ylab = colnames(diff)[2])
text(0,-1, paste("corr = ", round(cor(v$x,v$y),3)))
qqline(y)
y = diff[,2]
v=qqnorm(y, ylab = colnames(diff)[2])
text(0,-2, paste("corr = ", round(cor(v$x,v$y),3)))
qqline(y)
y = diff[,2]
v=qqnorm(y, ylab = colnames(diff)[2])
text(3,-2, paste("corr = ", round(cor(v$x,v$y),3)))
qqline(y)
phi<- function(x)    x^4*exp(x^2/4)
m  <-  10^6
sigma <- 1
mu <- 0
a <- 2
z <- rnorm(m)
z
is_est <- mean( h0*(z >a))
h0 <- phi(z)
h0is_est <- mean( h0*(z >a))
h0
f1=function(t){ t/(1+t*t)*exp(-(x-t)^2/2)}
f2=function(t){ 1/(1+t*t)*exp(-(x-t)^2/2)}
plot(f1,-3,3,col=1,ylim=c(-0.5,1),xlab="t",ylab="",ty="l")
plot(f2,-3,3,add=TRUE,col=2,ty="l")
legend("topright", c("f1=t.f2","f2"), lty=1,col=1 :2)
legend("topright", c("f1=t.f2","f2"), lty=1,col=1 :2)
f1=function(t){ t/(1+t*t)*exp(-(x-t)^2/2)}
f2=function(t){ 1/(1+t*t)*exp(-(x-t)^2/2)}
plot(f1,-3,3,col=1,ylim=c(-0.5,1),xlab="t",ylab="",ty="l")
plot(f2,-3,3,add=TRUE,col=2,ty="l")
legend("topright", c("f1=t.f2","f2"), lty=1,col=1 :2)
f1=function(t){ t/(1+t*t)*exp(-(x-t)^2/2)}
f2=function(t){ 1/(1+t*t)*exp(-(x-t)^2/2)}
plot(f1,-3,3,col=1,ylim=c(-0.5,1),xlab="t",ylab="",ty="l")
plot(f2,-3,3,add=TRUE,col=2,ty="l")
Niter=10^4
co=rcauchy(Niter)
I=mean(co*dnorm(co,mean=x))/mean(dnorm(co,mean=x))
I
x1=dnorm(co,mean=x)
estint2=cumsum(x1)/(1:Niter)
esterr2=sqrt(cumsum((x1-estint2)^2))/(1:Niter)
x1=co*x1
estint1=cumsum(x1))/(1:Niter)
esterr1=sqrt(cumsum((x1-estint1)^2))/(1:Niter)
par(mfrow=c(1,2))
plot(estint1,type="l",xlab="iteration",ylab="",col="gold")
lines(estint1-2*esterr1,lty=2,lwd=2)
lines(estint1+2*esterr1,lty=2,lwd=2)
plot(estint2,type="l",xlab="iteration",ylab="",col="gold")
lines(estint2-2*esterr2,lty=2,lwd=2)
x1=dnorm(co,mean=x)
estint2=cumsum(x1)/(1:Niter)
esterr2=sqrt(cumsum((x1-estint2)^2))/(1:Niter)
x1=co*x1
estint1=cumsum(x1))/(1:Niter)
estint1=cumsum(x1)/(1:Niter)
esterr1=sqrt(cumsum((x1-estint1)^2))/(1:Niter)
par(mfrow=c(1,2))
plot(estint1,type="l",xlab="iteration",ylab="",col="gold")
lines(estint1-2*esterr1,lty=2,lwd=2)
lines(estint1+2*esterr1,lty=2,lwd=2)
plot(estint2,type="l",xlab="iteration",ylab="",col="gold")
lines(estint2-2*esterr2,lty=2,lwd=2)
lines(estint2+2*esterr2,lty=2,lwd=2)
lines(estint2+2*esterr2,lty=2,lwd=2)
set.seed(1)
NSim <- 10^4
U <- runif(NSim)
X <- (-log(1-U)/lambda)^(1/3)
lambda <- 2
X <- (-log(1-U)/lambda)^(1/3)
mean.x=mean(x)
var.x=var(x)
x <- (-log(1-U)/lambda)^(1/3)
mean.x=mean(x)
var.x=var(x)
par(mfrow=c(1,1))
hist(x, freq=F, col= "grey", breaks =40,
main="Histogram: Generate random variable \
from F(x) using the inversion method")
set.seed(202009)
Nsim <- 10^4
set.seed(202009)
set.seed(1)
Nsim <- 10^4
r <- 2
f <- function(x) { dexp(x, 2)}
M <- optimize(f, interval =c(0,10), maximum =TRUE)$objective
M
y <- rexp(Nsim, r)
y <- rexp(Nsim, r)
u <- rexp(Nsim, r)
y <- rexp(Nsim, r)
u <- rexp(Nsim, r)
# since g(y)=1
x = y[u < dexp(y, r)/M ]
mean.x=mean(x)
mean.x
## [1] 0.6061904
# [1] 0.6061904
hist(x, freq=F, col= "grey", breaks =40, main="Compare simulation density of the true density")
s <- seq(0,1, length=100)
lines(s, dexp(x, r), lwd=2, col ="sienna")
s=seq(1,100,100)
s
s=seq(1,100,1)
s=seq(1,1.5,0.05)
s
s=seq(1,1.5,0.05)
s
s=seq(0,1.5,0.05)
s
s=seq(0,1.5,0.01)
s
matrix(c(0,0.5,0.5,0.5,0,0.5,0.5,0.5,0))
matrix(c(0,0.5,0.5,0.5,0,0.5,0.5,0.5,0),3,3)
m <-matrix(c(0,0.5,0.5,0.5,0,0.5,0.5,0.5,0),3,3)
m^1000
m^3
m^1000
m^1000
pexp(6, 1/4) - pexp(3,1/4)
x <- rexp(1000,1/4)
summary(x)
quantile(x,0.15)
qexp(0.15,1/4)
pexp(9.5,1/4)
1-pexp(9.5,1/4)
pnorm(0.75,0.64,0.09, lower.tail=FALSE)
pnorm(0.5,0.64,0.09)
qnorm(0.02,0.64,0.09,lower.tail=FALSE)
qnorm(1-0.02,0.64,0.09)
dbinom(6,26,0.5)
getwd()
read.csv("gender-classifier-DFE-791531.csv")
df <- read.csv("gender-classifier-DFE-791531.csv")
df <- read.csv("gender-classifier-DFE-791531.csv")
df <- read.csv("gender-classifier-DFE-791531.csv")
X <- data.frame(df$gender.confidence , df$tweet_count)
install.packages("factoextra")
library(factoextra)
km.res <- kmeans(df, 4, nstart=25)
km.res <- kmeans(X, 4, nstart=25)
X <- data.frame(df$gender.confidence , df$tweet_count)
head(df)
X <- na.rm(data.frame(df$gender.confidence , df$tweet_count))
km.res <- kmeans(X, 4, nstart=25)
head(x)
head(x, 10)
X <- matrxi(df$gender.confidence , df$tweet_count)
X <- matrix(df$gender.confidence , df$tweet_count)
head(x, 10)
names(df)
df$tweet_coord
X <- data.frame(col1 = df$gender.confidence, col2 = df$profile_yn.confidence)
head(x, 10)
head(X, 10)
X <- data.frame(col1 = df$gender.confidence, col2 = df$profile_yn.confidence, na.rm=TRUE)
head(X, 10)
X <- na.omit(data.frame(col1 = df$gender.confidence, col2 = df$profile_yn.confidence))
head(X, 10)
km.res <- kmeans(X, 2, nstart=25)
print(km.res)
km.res$cluster
library(ggpubr)
fviz_cluster(km.res, data = df[, -5],
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
fviz_cluster(km.res, data = X,
palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
install.packages("factoextra")
install.packages("installr")
library(installr)
updateR()
updateR()
source("libraries.R")
source("tweet-scraping.R")
source("data-transform.R")
# Load needed libraries and authenticate using Twitter tokens
load_libraries()
library(utils) #needed for the source to load installed.packages()
options(repos=c("https://cran.rstudio.com", getOption("repos") ) )
## designate packages to install/load
all_pkgs <- c("reticulate","png","RColorBrewer")
## find packages that need to be installed
already_installed <- rownames(installed.packages())
to_install <- setdiff(all_pkgs, already_installed)
if (length(to_install) > 0) {
install.packages(to_install, dependencies=TRUE)
}
library(utils) #needed for the source to load installed.packages()
options(repos=c("https://cran.rstudio.com", getOption("repos") ) )
## designate packages to install/load
all_pkgs <- c("factoextra","tidyverse","twitteR", "tidytext")
## find packages that need to be installed
already_installed <- rownames(installed.packages())
to_install <- setdiff(all_pkgs, already_installed)
if (length(to_install) > 0) {
install.packages(to_install, dependencies=TRUE)
}
library(utils) #needed for the source to load installed.packages()
options(repos=c("https://cran.rstudio.com", getOption("repos") ) )
# designate packages to install/load
all_pkgs <- c("factoextra","tidyverse","twitteR", "tidytext")
# find packages that need to be installed
already_installed <- rownames(installed.packages())
to_install <- setdiff(all_pkgs, already_installed)
if (length(to_install) > 0) {
install.packages(to_install, dependencies=TRUE)
}
# now load all packages
sapply(all_pkgs, library, character.only=TRUE, logical.return=TRUE)
source('C:/Users/surfacepro/Desktop/twitter-k-means/setup.R', echo=TRUE)
source("tweet-scraping.R")
source("data-transform.R")
# Choose topic word and create data frame used for algorithm
word <- "trump"
n <- 10
df_raw <- scrape_tweets(word, n)
df <- process_tweets(word,df_raw,n)
topic <- word
tweets <- df_raw
number_of_tweets <- n
exclude <- data.frame(word = c(topic,
paste0(topic, c("'s" , "âs", "s")),
"https",
"t.co",
"rt",
"amp",
"itâs",
paste0(1:100)))
# Create list of unwanted words
my_stop_words <- stop_words %>% select(-lexicon) %>%
bind_rows(exclude)
followers <- c()
user_created <- c()
location <- c()
total_tweets <- c()
for (i in 1:number_of_tweets) {
user <- getUser(tweets$screenName[i])
followers <- append(followers, user$followersCount)
user_created <- append(user_created, as.Date(user$created))
location <- append(location, user$location)
total_tweets <- append(total_tweets, user$statusesCount)
}
tweets$screenName
getUser("DinaJ")
getUser("DinaJ")
getUser("DinaJ")
# Choose topic word and create data frame used for algorithm
word <- "trump"
n <- 50
df_raw <- scrape_tweets(word, n)
df <- process_tweets(word,df_raw,n)
n <- 100
# Choose topic word and create data frame used for algorithm
word <- "trump"
n <- 100
df_raw <- scrape_tweets(word, n)
df <- process_tweets(word,df_raw,n)
source("tweet-scraping.R")
source("data-transform.R")
# Choose topic word and create data frame used for algorithm
word <- "trump"
n <- 300
df_raw <- scrape_tweets(word, n)
df <- process_tweets(word,df_raw,n)
# K means classifier
k_means <- kmeans(df,3,nstart=25)
fviz_cluster(k_means, data = df, labelsize=0)
# K means classifier
k_means <- kmeans(df,2,nstart=25)
fviz_cluster(k_means, data = df, labelsize=0)
# K means classifier
k_means <- kmeans(df,4,nstart=25)
fviz_cluster(k_means, data = df, labelsize=0)
source("tweet-scraping.R")
source("data-transform.R")
# Choose topic word and create data frame used for algorithm
word <- "trump"
n <- 400
df_raw <- scrape_tweets(word, n)
df <- process_tweets(word,df_raw,n)
# K means classifier
k_means <- kmeans(df,3,nstart=25)
fviz_cluster(k_means, data = df, labelsize=0)
